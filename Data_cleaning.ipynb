{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, Embedding, Flatten, concatenate, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import preprocessor as p\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "p.set_options(p.OPT.URL, p.OPT.NUMBER, p.OPT.RESERVED, p.OPT.MENTION)\n",
    "\n",
    "#bert_embedding = BertEmbedding(model='bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased')\n",
    "\n",
    "DATA_PATH = \"./data/tweet_no_dup.tsv\"\n",
    "GOOGLE_EMBEDDING_PATH = \"./data/GoogleNews-vectors-negative300.bin\"\n",
    "TWEET_EMBEDDING_PATH = \"./data/glove.twitter.27B.200d.txt\"\n",
    "MODEL_PATH = \"./CNN.model\"\n",
    "BASE_DIR = 'data'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "MAX_NUM_WORDS = 40000 #93428\n",
    "EMBEDDING_DIM = 200\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "def load_sentences_from_df(train_df, id_field = 'id', sentiment_label='label', tweet_field='tweet', lower=True, clean=True):\n",
    "    \"\"\"\n",
    "    Loads sentences.\n",
    "    :param train_df: pandas.DataFrame containing labeled tweets.\n",
    "    :return: sents (paired with labels), word doc freq, list of labels.\n",
    "    \"\"\"\n",
    "    sents = []\n",
    "    lbl = {'negative':0,\n",
    "           'neutral':1,\n",
    "          'positive':2}\n",
    "    ids = set()\n",
    "    word_df = defaultdict(int)        \n",
    "    for line in train_df.iterrows():\n",
    "        \n",
    "        if not(line[1][id_field] in ids):\n",
    "            ids.add(line[1][id_field])\n",
    "            tweet = line[1][tweet_field]\n",
    "            sentiment = line[1][sentiment_label]\n",
    "\n",
    "            clean_text = tweet.lower() if lower else text\n",
    "            clean_text = p.clean(clean_text) if clean else clean_text\n",
    "            clean_text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', re.sub(r'[^\\x00-\\x7f]',r'', clean_text)) if clean else clean_text\n",
    "\n",
    "            words = clean_text.split()\n",
    "            for word in set(words):\n",
    "                word_df[word] += 1\n",
    "            pair = (words, lbl[sentiment])\n",
    "            sents.append(pair)\n",
    "\n",
    "    labels = [0] * len(lbl)\n",
    "    for l,i in lbl.items():\n",
    "        labels[i] = l\n",
    "        \n",
    "    return sents, word_df, labels\n",
    "\n",
    "\n",
    "def load_sentences(train_file, tagField=1, textField=2, lower=True, no_dup = False, clean = True):\n",
    "    \"\"\"\n",
    "    Loads sentences.\n",
    "    :param train_file: filename containing labeled sentences in TSV format.\n",
    "    :return: sents (paired with labels), word doc freq, list of labels.\n",
    "    \"\"\"\n",
    "    sents = []\n",
    "    tags = {'negative':0,\n",
    "           'neutral':1,\n",
    "          'positive':2}\n",
    "    ids = set()\n",
    "    word_df = defaultdict(int)\n",
    "    with open(train_file, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:       \n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            try: \n",
    "                if no_dup:\n",
    "                    if not(fields[0] in ids):\n",
    "                        ids.add(fields[0])\n",
    "                        text = fields[textField]\n",
    "                        tag = fields[tagField]\n",
    "                        \n",
    "                        if lower:\n",
    "                            clean_text = text.lower()\n",
    "                        clean_text = p.clean(clean_text)\n",
    "                        words = clean_text.split()\n",
    "                        for word in set(words):\n",
    "                            word_df[word] += 1\n",
    "                        pair = (words, tags[tag])\n",
    "                        sents.append(pair)\n",
    "                else:\n",
    "                    text = fields[textField]\n",
    "                    tag = fields[tagField]\n",
    "                    \n",
    "                    if lower:\n",
    "                        clean_text = text.lower()\n",
    "                    clean_text = p.clean(clean_text)\n",
    "                    clean_text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', re.sub(r'[^\\x00-\\x7f]',r'', clean_text)) if clean else clean_text\n",
    "                    words = clean_text.split()\n",
    "                    for word in set(words):\n",
    "                        word_df[word] += 1\n",
    "                    pair = (words, tags[tag])\n",
    "                    sents.append(pair)\n",
    "            except(e):\n",
    "                print(e.Message())\n",
    "                continue;\n",
    "    labels = [0] * len(tags)\n",
    "    for tag,i in tags.items():\n",
    "        labels[i] = tag\n",
    "    return sents, word_df, labels\n",
    "\n",
    "def split(df, pct):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    result = []\n",
    "\n",
    "    for i in range(0,len(pct)):\n",
    "        end = start+int(len(df)*pct[i])\n",
    "        result.append(df.iloc[start:end])\n",
    "        start=end\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def createDatasets(df, labels, column, pct, shuffle=False):\n",
    "    \n",
    "    results_tmp = []\n",
    "    result = []\n",
    "    i=0\n",
    "    \n",
    "    for l in labels:\n",
    "        d_tmp = df[df[column]==l]\n",
    "        results_tmp.append(split(d_tmp,pct))\n",
    "\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        d=pd.DataFrame()\n",
    "        for j in range(0,len(labels)):\n",
    "            d=d.append(results_tmp[j][i])\n",
    "        if shuffle:\n",
    "            d=d.reindex(np.random.RandomState(seed=2).permutation(d.index))\n",
    "        result.append(d)\n",
    "\n",
    "    return result\n",
    "\n",
    "def macroaveraged_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute recall for each class and average the result (see SemEval2017)\n",
    "    :return: macroaveraged_recall.\n",
    "    \"\"\"\n",
    "    n_class = len(y_true[0])\n",
    "    true_vects = [[] for i in range(n_class)]\n",
    "    pred_vects = [[] for i in range(n_class)]\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(n_class):\n",
    "            true_vects[j].append(y_true[i][j])\n",
    "            pred_vects[j].append(y_pred[i][j])\n",
    "    \n",
    "    recalls = [ recall_score(true_vects[i], pred_vects[i]) for i in range(n_class)]\n",
    "    return recalls, np.average(recalls)\n",
    "\n",
    "def get_dummy(n_out, strategy='most_frequent'):\n",
    "    return np.array([[1., 0., 0.] for i in range(n_out)])\n",
    "\n",
    "def create_baseline():\n",
    "    tweet_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    tweet_encoder = Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                              input_length=MAX_SEQUENCE_LENGTH, trainable=True)(tweet_input)\n",
    "    bigram_branch = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "    trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "    fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "    merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "\n",
    "    merged = Dense(256, activation='relu')(merged)\n",
    "    merged = Dropout(0.2)(merged)\n",
    "    merged = Dense(3)(merged)\n",
    "    output = Activation('sigmoid')(merged)\n",
    "    model_ZW = Model(inputs=[tweet_input], outputs=[output])\n",
    "    model_ZW.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['categorical_accuracy'])\n",
    "    return model_ZW\n",
    "\n",
    "def get_test_data(test_sents, tokenizer, word_index):\n",
    "    test_text = []\n",
    "    test_labls = []\n",
    "\n",
    "    for s in test_sents:\n",
    "        test_text.append(s[0])\n",
    "        test_labls.append(s[1])\n",
    "\n",
    "    print('Found %s tweets.' % len(test_sents))\n",
    "\n",
    "    tokenizer.word_index = word_index\n",
    "    tokenizer.fit_on_texts(test_text)\n",
    "    tokenizer.word_index = word_index\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "    #test_word_index = word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    test_labels = to_categorical(np.asarray(test_labls))\n",
    "    \n",
    "    print('Shape of data tensor:', test_data.shape)\n",
    "    print('Shape of label tensor:', test_labels.shape)\n",
    "\n",
    "    x_test = test_data\n",
    "    y_test = test_labels\n",
    "    \n",
    "    return x_test, y_test\n",
    "\n",
    "def to_category(y_test_pred):\n",
    "    y_test_mod = []\n",
    "    for i in range(len(y_test_pred)):\n",
    "        tmp = y_test_pred[i]\n",
    "        y_test_mod.append([0.]*3)\n",
    "        y_test_mod[-1][tmp.argmax()] = 1.\n",
    "    y_test_mod = np.array(y_test_mod)\n",
    "    return y_test_mod\n",
    "\n",
    "\n",
    "def train_test_split_cv(x, y, n_iter, n_fold = 10):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "   \n",
    "    x=list(x)\n",
    "    y=list(y)\n",
    "    n_iter = n_fold if n_iter > n_fold else n_iter \n",
    "    ns_fold = int(len(x)/n_fold)\n",
    "    \n",
    "    test_start_idx = (n_iter-1)*ns_fold\n",
    "    test_end_idx = (n_iter)*ns_fold\n",
    "    \n",
    "#    print(\"Test starts at \"+str(test_start_idx)+\" ending at \"+str(test_end_idx))\n",
    "    x_train, y_train = [], []\n",
    "    \n",
    "    if test_start_idx == 0:\n",
    "        x_train = x[test_end_idx:]\n",
    "        y_train = y[test_end_idx:]\n",
    "    elif test_end_idx == len(x):\n",
    "        x_train = x[:test_start_idx]\n",
    "        y_train = y[:test_start_idx]\n",
    "    else:\n",
    "        x_train = x[:test_start_idx]+x[test_end_idx:] \n",
    "        y_train = y[:test_start_idx]+y[test_end_idx:] \n",
    "\n",
    "    x_test = x[test_start_idx:test_end_idx]\n",
    "    y_test = y[test_start_idx:test_end_idx]\n",
    "\n",
    "    \n",
    "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "def cross_validation(x, y, n_fold = 3, n_repeat = 1, **params):\n",
    "    #macro_averaged_recall, categorical accuracy on validation\n",
    "    results = []\n",
    "    batch_size=params['batch_size']\n",
    "    epochs=params['epochs']\n",
    "    ks = params['kernel_size']\n",
    "    nf = params['n_filter']\n",
    "    dropout = params['dropout']\n",
    "    \n",
    "    #random seed init\n",
    "    step_tot = 0\n",
    "    for it in range(n_repeat):\n",
    "        fold_res = []\n",
    "        for i in range(1, n_fold+1):\n",
    "            x_train, y_train, x_val, y_val = train_test_split_cv(x, y, i, n_fold=n_fold)\n",
    "            \n",
    "            model = create_model(kernel_size = ks, n_filter = nf, dropout = dropout)\n",
    "\n",
    "            model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "            #predict + scoring su test/validation\n",
    "            \n",
    "            step_tot+=1\n",
    "            y_pred = to_category(model.predict(x_val, batch_size = batch_size))\n",
    "            garb, mavg = macroaveraged_recall(y_val, y_pred)#, categorical_accuracy(y_val, y_pred)\n",
    "            \n",
    "            print(\"##################################################################\")\n",
    "            print(\"Step #\"+str(it+1)+\".\"+str(i)+\" (\"+str(step_tot)+\"/\"+str(n_repeat*n_fold)+\") mavg_recall on validation = \"+str(mavg)[:5])#+\" - ca = \"+str(ca))\n",
    "            print(\"##################################################################\")\n",
    "            \n",
    "            fold_res.append(mavg)\n",
    "        step_avg, step_std = np.average(fold_res), np.std(fold_res)\n",
    "        print(\"=========================> Average mavg_recall at step #\"+str(it+1)+\" = \"+str(step_avg)[:5]+\" +/-\"+str(step_std)[:5]+\"<=========================\")\n",
    "        results.append(step_avg)\n",
    "    \n",
    "    return np.average(results), np.std(results)\n",
    "\n",
    "def grid_search(x, y, n_fold = 3, n_repeat = 1, embedding = \"glovetweet200\", **param_grid):\n",
    "    results = dict({})\n",
    "    for batch in param_grid['batch_size']:\n",
    "        for ep in param_grid['epochs']:\n",
    "            for n_filter in param_grid['n_filters']:\n",
    "                for ker_size in param_grid['kernel_sizes']:\n",
    "                    params = dict({\n",
    "                        \"batch_size\":batch,\n",
    "                        \"epochs\":ep,\n",
    "                        \"n_filter\" : n_filter,\n",
    "                        \"kernel_size\" : ker_size,\n",
    "                        \"dropout\" : 0.\n",
    "                    })\n",
    "                    \n",
    "                    model_tag = \"b\"+str(batch)+\"-ep\"+str(ep)+\"-nf\"+str(n_filter)+\"-ks\"+str(ker_size)+\"-emb\"+str(embedding)\n",
    "                    print(\"Started a \"+str(n_fold)+\"-fold cv with \"+model_tag)\n",
    "                    results[model_tag] = cross_validation(x, y, n_fold = n_fold, n_repeat = n_repeat, **params)\n",
    "    return results\n",
    "        \n",
    "\n",
    "def create_model(kernel_size = (2, 3, 4), n_filter = (100, 100, 100), dropout = 0.):\n",
    "    tweet_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    tweet_encoder = Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                              input_length=MAX_SEQUENCE_LENGTH, trainable=True)(tweet_input)\n",
    "    bigram_branch = Conv1D(filters=n_filter[0], kernel_size=kernel_size[0], padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "    trigram_branch = Conv1D(filters=n_filter[1], kernel_size=kernel_size[1], padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "    fourgram_branch = Conv1D(filters=n_filter[2], kernel_size=kernel_size[2], padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "    fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "    merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "\n",
    "    merged = Dense(256, activation='relu')(merged)\n",
    "    merged = Dropout(dropout)(merged) if dropout > 0 else merged\n",
    "    merged = Dense(3)(merged)\n",
    "    output = Activation('sigmoid')(merged)\n",
    "    model_ZW = Model(inputs=[tweet_input], outputs=[output])\n",
    "    model_ZW.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['categorical_accuracy'])\n",
    "    return model_ZW\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(\"./data/tweet_no_dupid.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_tsv(path):\n",
    "    data = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for l in f:\n",
    "            rec = l[:-1].split('\\t')\n",
    "            if len(rec) == 3:\n",
    "                data.append(rec)\n",
    "    return pd.DataFrame(columns=['id', 'label', 'tweet'], data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with dup has 21826 records\n",
      "Train with no dup has 21240 records, 586 less.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000794790727680</td>\n",
       "      <td>positive</td>\n",
       "      <td>One Night like In Vegas I make dat Nigga Famous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000831528632320</td>\n",
       "      <td>positive</td>\n",
       "      <td>Walking through Chelsea at this time of day is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000950005145600</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\"And on the very first play of the night, Aaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000974885748736</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\"Drove the bike today, about 40 miles. Felt li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001038454624257</td>\n",
       "      <td>negative</td>\n",
       "      <td>looking at the temp outside....hpw did it get ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     label  \\\n",
       "0  100000794790727680  positive   \n",
       "1  100000831528632320  positive   \n",
       "2  100000950005145600   neutral   \n",
       "3  100000974885748736   neutral   \n",
       "4  100001038454624257  negative   \n",
       "\n",
       "                                               tweet  \n",
       "0    One Night like In Vegas I make dat Nigga Famous  \n",
       "1  Walking through Chelsea at this time of day is...  \n",
       "2  \"And on the very first play of the night, Aaro...  \n",
       "3  \"Drove the bike today, about 40 miles. Felt li...  \n",
       "4  looking at the temp outside....hpw did it get ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfs = [ df_from_tsv(\"./data/train/twitter-train\"+str(i)+\".txt\") for i in range(6)]\n",
    "train_df = pd.concat(train_dfs)\n",
    "print(\"Train with dup has \" + str(len(train_df)) + \" records\")\n",
    "no_dup = train_df.groupby(as_index=False, by=['id']).first()\n",
    "print(\"Train with no dup has \" + str(len(no_dup)) + \" records, \"+str(len(train_df)-len(no_dup))+\" less.\")\n",
    "no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup.to_csv(\"tweet-train-no_dup.tsv\", sep=\"\\t\", index=False)\n",
    "#nno_dup = pd.read_csv(\"tweet-train-no_dup.tsv\", sep=\"\\t\")\n",
    "#nno_dup.head()\n",
    "#len(nno_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 16991\n",
      "vocab size: 42130\n",
      "max sentence length: 33\n"
     ]
    }
   ],
   "source": [
    "tweet_df=createDatasets(no_dup,['positive','negative','neutral'],'label',[0.,0.8,0.2],shuffle=True)\n",
    "\n",
    "train_sents, word_df, train_labels = load_sentences_from_df(tweet_df[1])\n",
    "max_l = max(len(words) for words,l in train_sents)\n",
    "print( \"number of sentences: %d\" % len(train_sents))\n",
    "print( \"vocab size: %d\" % len(word_df))\n",
    "print( \"max sentence length: %d\" % max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "7017 neutral tweets 41.29% of total\n",
      "7286 positive tweets 42.88% of total\n",
      "2688 negative tweets 15.82% of total\n",
      "Test\n",
      "1754 neutral tweets 41.29% of total\n",
      "1821 positive tweets 42.87% of total\n",
      "672 negative tweets 15.82% of total\n"
     ]
    }
   ],
   "source": [
    "tweet = tweet_df[1]\n",
    "print(\"Train\")\n",
    "print(str(len(tweet[tweet['label'] == 'neutral']))+\" neutral tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'neutral'])*100./len(tweet))[:5]+\"% of total\")\n",
    "print(str(len(tweet[tweet['label'] == 'positive']))+\" positive tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'positive'])*100./len(tweet))[:5]+\"% of total\")\n",
    "print(str(len(tweet[tweet['label'] == 'negative']))+\" negative tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'negative'])*100./len(tweet))[:5]+\"% of total\")\n",
    "\n",
    "tweet = tweet_df[2]\n",
    "print(\"Test\")\n",
    "print(str(len(tweet[tweet['label'] == 'neutral']))+\" neutral tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'neutral'])*100./len(tweet))[:5]+\"% of total\")\n",
    "print(str(len(tweet[tweet['label'] == 'positive']))+\" positive tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'positive'])*100./len(tweet))[:5]+\"% of total\")\n",
    "print(str(len(tweet[tweet['label'] == 'negative']))+\" negative tweets \"+\n",
    "      str(len(tweet[tweet['label'] == 'negative'])*100./len(tweet))[:5]+\"% of total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build embedding index from GloVe-Twitter-.27B-200d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(TWEET_EMBEDDING_PATH, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16991 tweets.\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "labls = []\n",
    "\n",
    "for s in train_sents:\n",
    "    text.append(s[0])\n",
    "    labls.append(s[1])\n",
    "\n",
    "print('Found %s tweets.' % len(train_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42130 unique tokens.\n",
      "Shape of data tensor: (16991, 40)\n",
      "Shape of label tensor: (16991, 3)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(text)\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "train_labels = to_categorical(np.asarray(labls))\n",
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build embedding matrix for CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "high = 2.38 / np.sqrt(len(text) + EMBEDDING_DIM) # see (Bottou '88)\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else: \n",
    "        embedding_matrix[i] = np.random.uniform(-high, high, EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(file = open('embedding_matrixTW200', 'wb'), obj = embedding_matrix)\n",
    "pickle.dump(file = open('train_data', 'wb'), obj = train_data)\n",
    "pickle.dump(file = open('train_labels', 'wb'), obj = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4247 tweets.\n",
      "Found 42130 unique tokens.\n",
      "Shape of data tensor: (4247, 40)\n",
      "Shape of label tensor: (4247, 3)\n",
      "number of sentences: 4247\n",
      "vocab size: 14390\n",
      "max sentence length: 31\n"
     ]
    }
   ],
   "source": [
    "test_sents, test_word_df, test_labels_ = load_sentences_from_df(tweet_df[2])\n",
    "test_data, test_labels = get_test_data(test_sents, tokenizer, word_index)\n",
    "\n",
    "test_max_l = max(len(words) for words,l in test_sents)\n",
    "print( \"number of sentences: %d\" % len(test_sents))\n",
    "print( \"vocab size: %d\" % len(test_word_df))\n",
    "print( \"max sentence length: %d\" % test_max_l)\n",
    "\n",
    "pickle.dump(file = open('test_data', 'wb'), obj = test_data)\n",
    "pickle.dump(file = open('test_labels', 'wb'), obj = test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "We perform 3 5-fold cv for configuration $\\theta$ and average its scores. *grid_result* is a dictionary with one entry for each combination $\\theta_i$:\n",
    "\n",
    "model_tag : cv_score, cv_std\n",
    "\n",
    "where model_tag is a string that represents $\\theta_i$ and has this format:\n",
    "\n",
    "b *batch_size* -ep *epochs* -nf *n_filter* - ks *kernel_size* - emb *embedding* (see grid_search definition for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = dict({})\n",
    "grid_resut = pickle.load(open(\"grid_result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a 5-fold cv with b16-ep2-nf(100, 100, 100)-ks(2, 3, 4)\n",
      "Epoch 1/2\n",
      "39528/39528 [==============================] - 512s 13ms/step - loss: 0.8480 - categorical_accuracy: 0.4536\n",
      "Epoch 2/2\n",
      "39528/39528 [==============================] - 528s 13ms/step - loss: 0.6450 - categorical_accuracy: 0.5325\n",
      "##################################################################\n",
      "Step #1.1 (1/15) mavg_recall on validation = 0.596\n",
      "##################################################################\n",
      "Epoch 1/2\n",
      "24240/39528 [=================>............] - ETA: 3:24 - loss: 0.8348 - categorical_accuracy: 0.5722"
     ]
    }
   ],
   "source": [
    "#cross_validation(train_data, train_labels, n_repeat=4, n_fold=10)\n",
    "param_grid = dict({\n",
    "    \"batch_size\":[16,32,64,128],\n",
    "    \"epochs\":[2],\n",
    "    \"n_filters\" : [(100, 100, 100)],\n",
    "    \"kernel_sizes\" : [(2, 3, 4)]\n",
    "})\n",
    "\n",
    "grid_result.update(grid_search(train_data, train_labels, n_fold=5, n_repeat = 3, **param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get GridSearch Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_result_v = dict({})\n",
    "\n",
    "for k in grid_result.keys():\n",
    "    grid_result_v[k] = [grid_result[k][0],grid_result[k][1]]\n",
    "\n",
    "sorted(grid_result.items(), key = operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sents = [\" \".join(text[i]) for i in range(len(text))]\n",
    "input_sents = bert_embedding(bert_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = train_test_split_cv(train_data, train_labels, 1, n_fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Found 12352 tweets.\n",
      "Found 90630 unique tokens.\n",
      "Shape of data tensor: (12352, 40)\n",
      "Shape of label tensor: (12352, 3)\n"
     ]
    }
   ],
   "source": [
    "test_sents, test_word_df, test_labels_ = load_sentences_from_df(tweet_df[2])\n",
    "x_test, y_test = get_test_data(test_sents, tokenizer, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16470/16470 [==============================] - 4s 231us/step\n",
      "[0.4469895287958115, 0.6244518272425249, 0.7598913228052301]\n",
      "Validation marco-averaged recall = 0.61\n",
      "16470/16470 [==============================] - 4s 236us/step\n",
      "Validation loss: 0.805257450137344\n",
      "Validation accuracy: 0.6399514268221969\n",
      "12352/12352 [==============================] - 3s 237us/step\n",
      "[0.47898799313893653, 0.5756444444444444, 0.5899886234357224]\n",
      "Test marco-averaged recall = 0.54\n",
      "12352/12352 [==============================] - 3s 248us/step\n",
      "Test loss: 1.089451436242909\n",
      "Test accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "y_val_predZW = model_ZW.predict(x_val, batch_size=32, verbose=1)\n",
    "y_val_modZW = to_category(y_val_predZW)\n",
    "\n",
    "\n",
    "zwvrecalls, zwvavg_recall = macroaveraged_recall(y_val, y_val_modZW)\n",
    "print(zwvrecalls)\n",
    "print(\"Validation marco-averaged recall = \"+str(zwvavg_recall)[:4])\n",
    "\n",
    "zwvscores = model_ZW.evaluate(x_val, y_val, verbose=1)\n",
    "print('Validation loss:', zwvscores[0])\n",
    "print('Validation accuracy:', zwvscores[1])\n",
    "\n",
    "y_test_predZW = model_ZW.predict(x_test, batch_size=32, verbose=1)\n",
    "y_test_modZW = to_category(y_test_predZW)\n",
    "\n",
    "\n",
    "zwrecalls, zwavg_recall = macroaveraged_recall(y_test, y_test_modZW)\n",
    "print(zwrecalls)\n",
    "print(\"Test marco-averaged recall = \"+str(zwavg_recall)[:4])\n",
    "# Score trained model.\n",
    "zwscores = model_ZW.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', zwscores[0])\n",
    "print('Test accuracy:', zwscores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2094 tweets.\n",
      "Found 90630 unique tokens.\n",
      "Shape of data tensor: (2094, 40)\n",
      "Shape of label tensor: (2094, 3)\n",
      "Found 1142 tweets.\n",
      "Found 90630 unique tokens.\n",
      "Shape of data tensor: (1142, 40)\n",
      "Shape of label tensor: (1142, 3)\n"
     ]
    }
   ],
   "source": [
    "SMS_PATH = \"./data/sms-2013.tsv\"\n",
    "JOURNAL_PATH = \"./data/livej_no_dup.tsv\"\n",
    "\n",
    "model_ = model_ZW\n",
    "\n",
    "sms_sent, sms_word_df, sms_labels = load_sentences(SMS_PATH, tagField=2, textField=3)\n",
    "j_sent, j_word_df, j_labels = load_sentences(JOURNAL_PATH, tagField=2, textField=1, no_dup = False)\n",
    "x_sms, y_sms = get_test_data(sms_sent, tokenizer, word_index)\n",
    "x_journ, y_journ = get_test_data(j_sent, tokenizer, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2094/2094 [==============================] - 0s 235us/step\n",
      "1142/1142 [==============================] - 0s 245us/step\n"
     ]
    }
   ],
   "source": [
    "y_sms_pred = model_ZW.predict(x_sms, batch_size=32, verbose=1)\n",
    "y_j_pred = model_ZW.predict(x_journ, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3629441624365482, 0.7706953642384106, 0.556910569105691]\n",
      "SMS marco-averaged recall = 0.56\n",
      "2094/2094 [==============================] - 0s 234us/step\n",
      "Test loss: 0.8319354089761531\n",
      "Test accuracy: 0.6437440306773727\n",
      "[0.40460526315789475, 0.6666666666666666, 0.7189695550351288]\n",
      "J marco-averaged recall = 0.59\n",
      "1142/1142 [==============================] - 0s 234us/step\n",
      "Test loss: 0.8358790920411225\n",
      "Test accuracy: 0.6164623467600701\n"
     ]
    }
   ],
   "source": [
    "y_sms_mod = to_category(y_sms_pred)\n",
    "y_j_mod = to_category(y_j_pred)\n",
    "\n",
    "srecalls, savg_recall = macroaveraged_recall(y_sms, y_sms_mod)\n",
    "print(srecalls)\n",
    "print(\"SMS marco-averaged recall = \"+str(savg_recall)[:4])\n",
    "sms_scores = model_ZW.evaluate(x_sms, y_sms, verbose=1)\n",
    "print('Test loss:', sms_scores[0])\n",
    "print('Test accuracy:', sms_scores[1])\n",
    "\n",
    "jrecalls, javg_recall = macroaveraged_recall(y_journ, y_j_mod)\n",
    "print(jrecalls)\n",
    "print(\"J marco-averaged recall = \"+str(javg_recall)[:4])\n",
    "j_scores = model_ZW.evaluate(x_journ, y_journ, verbose=1)\n",
    "print('Test loss:', j_scores[0])\n",
    "print('Test accuracy:', j_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Validation | Test | SMS | LiveJournal |\n",
    "|:-----:|:-------------------:|:-----------------:|:---------------:|:-----------------------:|\n",
    "|  CNN_(3,4,5)x100 |         0.63 - 0.61         |        0.56 - 0.54       |     0.64 - 0.56      |          0.61 - 0.59          |\n",
    "|  baseline |             ?   |        0.33       |       0.33      |           0.33          |\n",
    "|  dummy |             ?   |        0.33       |       0.33      |           0.33          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on most important parameters\n",
    "\n",
    "The baseline configuration was ep2-nf(100, 100, 100)-ks(2, 3, 4) with no dropout. We tested:\n",
    "\n",
    "- batch_size\n",
    "- #epochs\n",
    "- nf\n",
    "- ker_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Validation | \n",
    "|:-----:|:-------------------:|\n",
    "batch_size 16  | 0.578 $ \\pm $0.123\n",
    "batch_size 32 | **0.649 $ \\mathbf{\\pm} $0.016**\n",
    "batch_size 64 | 0.644 $ \\pm $0.023\n",
    "batch_size 128 | 0.630 $ \\pm $0.040\n",
    "batch_size 256 | 0.632 $ \\pm $0.016\n",
    "batch_size 512 | 0.473 $ \\pm $0.135\n",
    "batch_size 1024 | 0.446 $ \\pm $0.133\n",
    "batch_size 2048 | 0.343 $ \\pm $0.037\n",
    "batch_size 4096 | 0.364 $ \\pm $0.043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Validation | \n",
    "|:-----:|:-------------------:|\n",
    "ks(1, 1, 1) | 0.638 $ \\pm $0.031\n",
    "ks(2, 2, 2) | 0.637 $ \\pm $0.014\n",
    "ks(3, 3, 3) | 0.636 $ \\pm $0.020\n",
    "ks(4, 4, 4) | **0.643 $ \\pm $0.028**\n",
    "ks(5, 5, 5) | 0.634 $ \\pm $0.018\n",
    "ks(6, 6, 6) | 0.640 $ \\pm $0.018\n",
    "ks(7, 7, 7) | 0.575 $ \\pm $0.115\n",
    "ks(8, 8, 8) | 0.635 $ \\pm $0.024\n",
    "ks(9, 9, 9) | **0.644 $ \\pm $0.020**\n",
    "ks(10, 10, 10) | **0.644 $ \\pm $0.017**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "mar_score = make_scorer(macroaveraged_recall, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_wrapped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ffa20f06bbef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_wrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmar_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_wrapped' is not defined"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(model_wrapped, x_train, y_train,scoring=mar_score, cv=5, verbose = 1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 tweets.\n",
      "Found 90630 unique tokens.\n",
      "Shape of data tensor: (1, 40)\n",
      "Shape of label tensor: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "x_ciao, y_ciao = get_test_data([([\"I\", \"am\", \"so\", \"safas\", \"that\", \"I\", \"will\", \"#happyness\"],1)], tokenizer, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28645733, 0.62810594, 0.52667683]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ZW.predict(x_ciao, batch_size=32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
